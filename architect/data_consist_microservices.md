# Согласованность данных в микросервисах

Полное руководство — от философии до конкретных паттернов.

---

## 1. Базовое разделение: сильная vs eventual согласованность

В микросервисах почти всегда приходится выбирать между двумя подходами:

### Сильная (strong) согласованность

Поведение как в монолите/одной БД: либо всё записалось, либо ничего.

**Обычно достигается:**
- Общая БД
- Распределённые транзакции (2PC, XA)

**Плюсы:**
- ✅ Проще для бизнеса и разработчиков

**Минусы:**
- ❌ Тесная связанность сервисов
- ❌ Проблемы с масштабированием
- ❌ Сложность и хрупкость распределённых транзакций

### Eventual consistency (постепенная согласованность)

Состояние сервисов может некоторое время расходиться, но "через какое-то время" всё выравнивается.

**Достигается через:**
- События
- Асинхронные очереди
- Ретраи и компенсации

**Плюсы:**
- ✅ Масштабируемость
- ✅ Независимость сервисов
- ✅ Устойчивость

**Минусы:**
- ❌ Сложнее рассуждать о системе
- ❌ Нужны паттерны и дисциплина

> Чаще всего в реальных системах — **гибрид**: критичные куски ближе к strong, остальное — event-driven.

---

## 2. Стратегии на уровне архитектуры

### 2.1. Общая БД vs Database per service

| Подход | Описание | Плюсы | Минусы |
|--------|----------|-------|--------|
| **Shared database** | Несколько сервисов ходят в одну БД | Легко для согласованности | Плохо для независимости и эволюции схемы |
| **Database per service** | У каждого сервиса своя БД | Независимость, эволюция | Согласованность решается паттернами |

> **Database per service** — правильный микросервисный подход. Взаимодействие только через API/события.

---

## 3. Паттерны согласованности между сервисами

### 3.1. Сага (Saga pattern)

**Идея:** Длинная бизнес-операция разбита на локальные транзакции в разных сервисах, связанных цепочкой. Если что-то падает, запускаются компенсационные действия.

#### Варианты реализации

**A. Оркестровка (Orchestration saga)**

Есть «оркестратор» (отдельный сервис/процесс), который:
1. Отправляет команду сервису A → ждёт успех/отказ
2. Затем команду сервису B → и т.д.
3. При ошибке вызывает компенсационные операции A', B', ...

**Плюсы:**
- ✅ Централизованная логика

**Минусы:**
- ❌ Оркестратор становится важной точкой сложностей

**B. Хореография (Choreography saga)**

Нет центра; сервисы реагируют на события друг друга:

```
OrderCreated 
  → PaymentService 
  → PaymentCompleted 
  → InventoryService 
  → InventoryReserved
```

Компенсация тоже через события: `PaymentFailed`, `InventoryRelease`.

**Плюсы:**
- ✅ Нет центрального "бога"
- ✅ Хорошая декомпозиция

**Минусы:**
- ❌ Сложнее понять общий сценарий
- ❌ Возможны "танцы на событиях" и хаос

**Когда использовать:**  
Любые кросс-сервисные бизнес-операции: заказ, бронирование, биллинг, ордеры.

---

### 3.2. Outbox pattern + событийная модель

**Проблема:**  
Как гарантировать, что и данные в БД записались, и событие ушло в брокер (Kafka/Rabbit) без рассинхрона?

**Решение — Transactional Outbox:**

**Шаг 1:** В рамках одной локальной транзакции:
- Пишем бизнес-данные (например, таблица `orders`)
- Пишем событие в таблицу `outbox`

**Шаг 2:** Отдельный процесс/воркер:
- Читает `outbox`
- Публикует события в брокер
- Помечает их как отправленные

**Плюс:**  
Нет "дырок" типа: данные записали, событие не ушло / наоборот.

> Часто комбинируется с **Change Data Capture (CDC)**, когда события берутся из WAL/логов БД.

---

### 3.3. Event Sourcing

Не столько "как всё синхронно", сколько подход к хранению:

- **Храним не состояние, а поток событий**, которые к нему привели
- Текущее состояние = результат применения всех событий

**Для микросервисов:**
- Каждая важная операция → доменное событие
- Другие сервисы подписываются и строят свои "проекции" (read-модели)

**Согласованность здесь по сути eventual:**
- Событие прошло → подписчики обновили свои проекции → через время все выровнялись

---

### 3.4. CQRS (Command Query Responsibility Segregation)

Разделяем модель на:

| Сторона | Назначение |
|---------|------------|
| **Command side** | Пишу (изменяю) данные, жёсткие инварианты, доменная логика |
| **Query side** | Читаю данные, оптимизированные под чтение (агрегированные/каталоги) |

**В связке микросервисов:**
- Один сервис может быть "источником правды" (command)
- Другие держат свои копии/кэши (query) через события

**Согласованность:**  
Чтения могут отставать от записей → eventual consistency, но в обмен на масштаб и быстрые запросы.

---

### 3.5. Идемпотентность и ретраи

Для согласованности при сбоях и сетевых глюках:

**Идемпотентные операции:**  
Повтор одного и того же сообщения/запроса не меняет результат.

**Использование идемпотентных ключей:**
- `request_id`, `operation_id`, `message_id`
- Сервис хранит, что по этому ID уже выполнял операцию → просто возвращает результат

**Ретраи с backoff:**  
Повторы при временных ошибках.

> At-least-once доставка + идемпотентность → гарантируем, что бизнес-инварианты не нарушатся.

⚠️ **Без идемпотентности** любые ретраи/дубликаты событий → лавина неконсистентности.

---

### 3.6. Distributed lock / лидерство

Иногда нужен "почти-strong" консистентный участок:

- Распределённые блокировки (Redis, etcd, Zookeeper)
- Лидер-выбор (leader election), и только лидер изменяет критичные данные

**Это уменьшает вероятность гонок, но:**
- ❌ Усложняет архитектуру
- ❌ Создаёт точки отказа/бутылочные горлышки

**Используют точечно:** биллинг, инвентаризация, лимиты.

---

### 3.7. Компенсации, дедупликация, dead-letter очереди

Часть общей стратегии согласованности:

**Компенсационные транзакции:**  
Как в Saga — откат изменений.

**Дедупликация сообщений:**
- Сохранение обработанных `message_id`
- Фильтрация дубликатов

**Dead-letter queue:**
- Сообщения, которые многократно не удалось обработать
- Выносятся в отдельную очередь/таблицу для ручного разруливания
- Не ломают поток

---

## 4. Подходы на уровне API / интеграций

### 4.1. Согласованность при синхронных вызовах (REST/gRPC)

Если один запрос идёт через цепочку сервисов:

**Пограничные инварианты:**
- Определяем, какие проверки/валидации делает каждый сервис
- Что гарантируется до и после вызова

**Time-outs, circuit breaker:**
- Вместо того, чтобы зависнуть, лучше вернуть "pending" и продолжить асинхронно

**TCC (Try-Confirm/Cancel):**
1. Сервис сначала делает "reserve" ресурса (try)
2. Потом явный confirm или cancel

Вариант саги, но чаще в более финансово-критичных вещах.

---

### 4.2. Версионирование и эволюция контрактов

Чтобы не ломать согласованность при изменениях:

- Версионирование API (v1/v2)
- Эволюция схемы событий (schema registry, backward/forward compatible)
- Правило: **"расширяй, не ломай"**

---

## 5. Организационные подходы

Согласованность — не только техника, но и процесс:

### Чётко описанные инварианты

Что в системе всегда должно быть истинно?
- Баланс не может быть отрицательным
- Заказ не может быть оплачен без резерва товара

### Контракты между доменами (DDD, Bounded Contexts)

- Кто за что отвечает?
- Где "источник правды" по каждому виду данных?

### Мониторинг и алерты

Метрики на:
- Лаг событий
- Расхождения агрегатов
- Количество сообщений в DLQ

### Регулярные reconciliation jobs

Ночные/периодические джобы, которые сверяют данные между сервисами и чинят расхождения.

---

## 6. Краткое резюме по слоям

| Уровень | Подходы |
|---------|---------|
| **Архитектурный** | Database per service, DDD/Bounded Contexts, выбор strong/eventual |
| **Интеграционный** | Saga, Outbox + брокер, Event Sourcing + CQRS, TCC, distributed locks |
| **Технический** | Идемпотентность + ретраи, дедупликация + DLQ, версионирование API |
| **Процессный** | Описанные инварианты, reconciliation jobs, мониторинг рассогласованности |

---

## Основные минусы микросервисной архитектуры

### 1. Существенная усложнённость системы

Микросервисы добавляют множество движущихся частей:

- Десятки/сотни сервисов
- Сеть между ними
- Брокеры событий
- Конфигурации, секреты, CI/CD
- Сервис-меш, API-gateway
- Мониторинг, логирование, трассировка

В монолите — один деплой, одна кодовая база.  
В микросервисах — целая экосистема.

> ⚠️ **Почему это проблема:**  
> Команда должна уметь строить распределённые системы. Без опыта — хаос, непредсказуемые фейлы, "микромонолиты" и частые продакшн-инциденты.

---

### 2. Усложнение отладки и трейсинга

| Монолит | Микросервисы |
|---------|--------------|
| Ошибка → смотрим лог → нашли | Запрос проходит через 5–20 сервисов |
| Один процесс | Каждый может ретраить |
| Синхронное выполнение | Часть работает асинхронно |

**Последствия:**
- ❌ Трудно понять, где сломалось
- ❌ Трудно воспроизвести баг
- ❌ Логов слишком много и они размазаны
- ⚠️ Без распределённого трейсинга (Jaeger, Zipkin, OpenTelemetry) вообще не живут

---

### 3. Сложность поддержания согласованности данных

Это фундаментальная проблема.

**Почему:**
- Каждая база своя
- Транзакции не работают между сервисами
- Нет ACID на весь бизнес-процесс
- Приходится использовать саги, outbox, event-driven

**Итог:**
- Частичная несовместимость данных неизбежна
- Бизнес агрится: "почему пользователь видит статус 'Paid', а склад считает заказ неоплаченным?"

> Это цена за независимость сервисов.

---

### 4. Рост сетевой нагрузки и латентности

В монолите вызов — это вызов функции.

В микросервисах:
- HTTP/gRPC
- Сериализация/десериализация
- Сетевые задержки
- Возможные timeouts
- Повторные попытки (retry storm)

**Как следствие:**
- Производительность ниже
- Нужен грамотный тайминг, троттлинг, circuit breaking
- Сеть становится критически важным "органом" системы

---

### 5. Сложности в DevOps и CI/CD

Не "один деплой", а:

- Десятки пайплайнов
- Артефакты сервисов
- Версии контрактов
- Миграции баз
- Канареечные релизы
- Независимые графики выката

**Боль:**
- Запуск кластера на локальном ноуте → почти невозможен без Docker Compose/K8s + имитации брокеров
- Огромная зависимость от DevOps-инфраструктуры

---

### 6. Повышенная стоимость инфраструктуры

Микросервисы редко дешевле. Они обычно **дороже**, потому что для каждого сервиса нужно:

| Компонент | Зачем |
|-----------|-------|
| CPU / RAM | Масштабирование |
| Отдельные базы/кластеры | Изоляция |
| Сервис-меш (Istio/Linkerd) | Service discovery, routing |
| Логирование (ELK/EFK) | Централизованные логи |
| Мониторинг (Prometheus) | Метрики |
| Очереди (Kafka, RabbitMQ) | Асинхронность |
| API GW (Kong, Traefik) | Единая точка входа |
| Discovery (Consul, Eureka) | Service registry |

> Даже на небольшом проекте быстро растёт счет от облака.

---

### 7. Высокие требования к компетенциям

Для успешных микросервисов команда должна понимать:

- DDD, Bounded Context
- CQRS, Event Sourcing
- Асинхронные коммуникации
- Конечные автоматы / саги
- Outbox
- Отказоустойчивость и ретраи
- Kubernetes
- Сервис-меш
- Распределённые транзакции (и почему их избегают)
- Eventual consistency

**Без этого микросервисы превращаются в:**

- ❌ "Распил монолита на N HTTP-сервисов"
- ❌ "Когда что-то падает — никто не знает, почему"
- ❌ "Цинковый гроб: не работает и собрать обратно нельзя"

---

### 8. Повышенная связанность через сеть

Есть вероятность:

- "Лавины ретраев"
- "Цепных таймаутов"
- "Каскадных сбоев": упал один сервис → очередь переполнилась → другие легли следом

**Требуется:**
- Circuit breaker
- Backpressure
- Rate-limits
- Bulkheads

> Монолитом это почти невозможно убить — там другое.

---

### 9. Сложность управления версиями API и контрактами

**Проблема эволюции:**
- Сервис A обновился → сервис B начал падать, потому что контракт изменился
- Нужно поддерживать backward/forward compatibility
- Нужен подход с Contract Testing (Pact)
- Нужен schema registry для событий

> Без дисциплины → бардак и "контрактные войны".

---

### 10. Сложнее тестировать

| Тип теста | Монолит | Микросервисы |
|-----------|---------|--------------|
| Unit | Легко | Легко |
| Интеграционные | Легко | Сложно |
| End-to-end | Один сервис | 5–30 сервисов |
| Нагрузочные | Один компонент | Много компонентов |
| Хаос-тесты | Редко | Обязательны |

**Детально:**
- Нужен тест-контур, включая брокеры, базы, очереди
- Много флейки-тестов из-за сетевых задержек
- Огромные трудозатраты на подготовку окружения

---

### 11. Рост операционных рисков

Много сервисов → много точек отказа.

**Проблемы:**
- Утечки памяти в одном микросервисе → срабатывают ретраи → нагрузка на соседей → система падает
- Проблемы в брокере событий → блокировка всей бизнес-цепочки
- Ошибки конфигурации между окружениями

---

### 12. Искажённая мотивация разработчиков

Психологический фактор:

- Каждый хочет "свой сервис" → сервисов становится слишком много
- Границы контекстов размыты
- "Микросервис ради микросервиса" → антипаттерн

> Иногда правильный ответ — **модульный монолит**, но команды выбирают микросервисы "потому что модно".

---

### 13. Сложности найма и онбординга

| Монолит | Микросервисы |
|---------|--------------|
| Открыл проект — видит всё | Не знает, где искать бизнес-логику |
| Быстрый старт | Не понимает зависимости |
| | 3 недели изучает инфраструктуру |

> Обучение становится дорогостоящим.

---

## Когда микросервисы — зло?

### ❌ Микросервисы BAD CHOICE, если:

- Мало команда (<10–15 разработчиков)
- Слабая культура DevOps/SRE
- Нет строгих требований к масштабированию
- Нет чёткого доменного деления
- Бизнес-процессы тесно связаны и требуют ACID
- Проект стартапный, быстро меняющийся

---

## Когда они действительно нужны?

### ✅ Микросервисы — правильный выбор, когда:

- Большая команда (30–200+ инженеров)
- Независимые доменные области
- Высокая нагрузка
- Нужны независимые релизы
- Критична отказоустойчивость
- Обязателен горизонтальный скейлинг и SLA
- Есть опыт построения распределённых систем

---

## Связь с другими практиками

Согласованность данных в микросервисах связана с:

- **DDD (Domain-Driven Design)** — Bounded Contexts, источники правды
- **Event-Driven Architecture** — асинхронность, брокеры
- **CQRS / Event Sourcing** — разделение чтения/записи
- **Saga Pattern** — распределённые транзакции
- **CAP-теорема** — выбор между consistency и availability
- **DevOps / SRE** — мониторинг, трейсинг, алертинг
